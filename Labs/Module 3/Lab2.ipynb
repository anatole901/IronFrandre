{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 1 - Import and Describe the Dataset\n",
    "In this challenge we will use the austin_weather.csv file.\n",
    "First import it into a data frame called austin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TempHighF</th>\n",
       "      <th>TempAvgF</th>\n",
       "      <th>TempLowF</th>\n",
       "      <th>DewPointHighF</th>\n",
       "      <th>DewPointAvgF</th>\n",
       "      <th>DewPointLowF</th>\n",
       "      <th>HumidityHighPercent</th>\n",
       "      <th>HumidityAvgPercent</th>\n",
       "      <th>HumidityLowPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>SeaLevelPressureAvgInches</th>\n",
       "      <th>SeaLevelPressureLowInches</th>\n",
       "      <th>VisibilityHighMiles</th>\n",
       "      <th>VisibilityAvgMiles</th>\n",
       "      <th>VisibilityLowMiles</th>\n",
       "      <th>WindHighMPH</th>\n",
       "      <th>WindAvgMPH</th>\n",
       "      <th>WindGustMPH</th>\n",
       "      <th>PrecipitationSumInches</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>93</td>\n",
       "      <td>75</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>29.68</td>\n",
       "      <td>29.59</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Rain , Thunderstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>30.13</td>\n",
       "      <td>29.87</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>30.49</td>\n",
       "      <td>30.41</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>30.45</td>\n",
       "      <td>30.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>30.33</td>\n",
       "      <td>30.27</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  TempHighF  TempAvgF  TempLowF DewPointHighF DewPointAvgF  \\\n",
       "0  2013-12-21         74        60        45            67           49   \n",
       "1  2013-12-22         56        48        39            43           36   \n",
       "2  2013-12-23         58        45        32            31           27   \n",
       "3  2013-12-24         61        46        31            36           28   \n",
       "4  2013-12-25         58        50        41            44           40   \n",
       "\n",
       "  DewPointLowF HumidityHighPercent HumidityAvgPercent HumidityLowPercent  ...  \\\n",
       "0           43                  93                 75                 57  ...   \n",
       "1           28                  93                 68                 43  ...   \n",
       "2           23                  76                 52                 27  ...   \n",
       "3           21                  89                 56                 22  ...   \n",
       "4           36                  86                 71                 56  ...   \n",
       "\n",
       "  SeaLevelPressureAvgInches SeaLevelPressureLowInches VisibilityHighMiles  \\\n",
       "0                     29.68                     29.59                  10   \n",
       "1                     30.13                     29.87                  10   \n",
       "2                     30.49                     30.41                  10   \n",
       "3                     30.45                      30.3                  10   \n",
       "4                     30.33                     30.27                  10   \n",
       "\n",
       "  VisibilityAvgMiles VisibilityLowMiles WindHighMPH WindAvgMPH WindGustMPH  \\\n",
       "0                  7                  2          20          4          31   \n",
       "1                 10                  5          16          6          25   \n",
       "2                 10                 10           8          3          12   \n",
       "3                 10                  7          12          4          20   \n",
       "4                 10                  7          10          2          16   \n",
       "\n",
       "  PrecipitationSumInches               Events  \n",
       "0                   0.46  Rain , Thunderstorm  \n",
       "1                      0                       \n",
       "2                      0                       \n",
       "3                      0                       \n",
       "4                      T                       \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin = pd.read_csv(r\"C:\\Users\\anato\\Documents\\IRONHACK\\DAFT_1022\\module_3\\Lab_2_Intro-to-ML\\austin_weather.csv\")\n",
    "austin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, describe the dataset you have loaded:\n",
    "Look at the variables and their types\n",
    "Examine the descriptive statistics of the numeric variables\n",
    "Look at the first five rows of all variables to evaluate the categorical variables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Date                        1319 non-null   object\n",
      " 1   TempHighF                   1319 non-null   int64 \n",
      " 2   TempAvgF                    1319 non-null   int64 \n",
      " 3   TempLowF                    1319 non-null   int64 \n",
      " 4   DewPointHighF               1319 non-null   object\n",
      " 5   DewPointAvgF                1319 non-null   object\n",
      " 6   DewPointLowF                1319 non-null   object\n",
      " 7   HumidityHighPercent         1319 non-null   object\n",
      " 8   HumidityAvgPercent          1319 non-null   object\n",
      " 9   HumidityLowPercent          1319 non-null   object\n",
      " 10  SeaLevelPressureHighInches  1319 non-null   object\n",
      " 11  SeaLevelPressureAvgInches   1319 non-null   object\n",
      " 12  SeaLevelPressureLowInches   1319 non-null   object\n",
      " 13  VisibilityHighMiles         1319 non-null   object\n",
      " 14  VisibilityAvgMiles          1319 non-null   object\n",
      " 15  VisibilityLowMiles          1319 non-null   object\n",
      " 16  WindHighMPH                 1319 non-null   object\n",
      " 17  WindAvgMPH                  1319 non-null   object\n",
      " 18  WindGustMPH                 1319 non-null   object\n",
      " 19  PrecipitationSumInches      1319 non-null   object\n",
      " 20  Events                      1319 non-null   object\n",
      "dtypes: int64(3), object(18)\n",
      "memory usage: 216.5+ KB\n"
     ]
    }
   ],
   "source": [
    "austin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the DewPointAvgF variable by using the unique() function to list all unique values in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['49', '36', '27', '28', '40', '39', '41', '26', '42', '22', '48',\n",
       "       '32', '8', '11', '45', '55', '61', '37', '47', '25', '23', '20',\n",
       "       '33', '30', '29', '17', '14', '13', '54', '59', '15', '24', '34',\n",
       "       '35', '57', '50', '53', '60', '46', '56', '51', '31', '38', '62',\n",
       "       '43', '63', '64', '67', '66', '58', '70', '68', '65', '69', '71',\n",
       "       '72', '-', '73', '74', '21', '44', '52', '12', '75', '76', '18'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin['DewPointAvgF'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe what you find in a markdown cell below the code. What did you notice? What do you think made Pandas to treat this column as object instead of int64?\n",
    "\n",
    "'-' is the entry that makes this field's type object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of columns misrepresented as object. Use this list to convert the columns to numeric using the pandas.to_numeric function in the next cell. If you encounter errors in converting strings to numeric values, you need to catch those errors and force the conversion by supplying errors='coerce' as an argument for pandas.to_numeric. Coercing will replace non-convertable elements with NaN which represents an undefined numeric value. This makes it possible for us to conveniently handle missing values in subsequent data processing.\n",
    "\n",
    "Hint: you may use a loop to change one column at a time but it is more efficient to use apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_type_columns = ['DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', \n",
    "                      'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', \n",
    "                      'SeaLevelPressureAvgInches' ,'SeaLevelPressureLowInches', 'VisibilityHighMiles',\n",
    "                      'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', \n",
    "                      'WindGustMPH', 'PrecipitationSumInches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin[wrong_type_columns] = austin[wrong_type_columns].apply(lambda x : pd.to_numeric(x, errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your code has worked by printing the data types again. You should see only two object columns (Date and Events) now. All other columns should be int64 or float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        1319 non-null   object \n",
      " 1   TempHighF                   1319 non-null   int64  \n",
      " 2   TempAvgF                    1319 non-null   int64  \n",
      " 3   TempLowF                    1319 non-null   int64  \n",
      " 4   DewPointHighF               1312 non-null   float64\n",
      " 5   DewPointAvgF                1312 non-null   float64\n",
      " 6   DewPointLowF                1312 non-null   float64\n",
      " 7   HumidityHighPercent         1317 non-null   float64\n",
      " 8   HumidityAvgPercent          1317 non-null   float64\n",
      " 9   HumidityLowPercent          1317 non-null   float64\n",
      " 10  SeaLevelPressureHighInches  1316 non-null   float64\n",
      " 11  SeaLevelPressureAvgInches   1316 non-null   float64\n",
      " 12  SeaLevelPressureLowInches   1316 non-null   float64\n",
      " 13  VisibilityHighMiles         1307 non-null   float64\n",
      " 14  VisibilityAvgMiles          1307 non-null   float64\n",
      " 15  VisibilityLowMiles          1307 non-null   float64\n",
      " 16  WindHighMPH                 1317 non-null   float64\n",
      " 17  WindAvgMPH                  1317 non-null   float64\n",
      " 18  WindGustMPH                 1315 non-null   float64\n",
      " 19  PrecipitationSumInches      1195 non-null   float64\n",
      " 20  Events                      1319 non-null   object \n",
      "dtypes: float64(16), int64(3), object(2)\n",
      "memory usage: 216.5+ KB\n"
     ]
    }
   ],
   "source": [
    "austin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 2 - Handle the Missing Data\n",
    "Now that we have fixed the type mismatch, let's address the missing data.\n",
    "By coercing the columns to numeric, we have created NaN for each cell containing characters. We should choose a strategy to address these missing data.\n",
    "\n",
    "The first step is to examine how many rows contain missing data.\n",
    "\n",
    "We check how much missing data we have by applying the .isnull() function to our dataset. To find the rows with missing data in any of its cells, we apply .any(axis=1) to the function. austin.isnull().any(axis=1) will return a column containing true if the row contains at least one missing value and false otherwise. Therefore we must subset our dataframe with this column. This will give us all rows with at least one missing value.\n",
    "\n",
    "In the next cell, identify all rows containing at least one missing value. Assign the dataframes with missing values to a variable called missing_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = austin.loc[austin.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we will use a hybrid approach which is to first remove the data that contain most missing values then fill in the rest of the missing values with the linear interpolation algorithm.\n",
    "Next, count the number of rows of austin and missing_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the number of missing rows in each column using the .isna() function. We then chain the .sum function to the .isna() function and find the number of missing rows per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                            0\n",
       "TempHighF                       0\n",
       "TempAvgF                        0\n",
       "TempLowF                        0\n",
       "DewPointHighF                   7\n",
       "DewPointAvgF                    7\n",
       "DewPointLowF                    7\n",
       "HumidityHighPercent             2\n",
       "HumidityAvgPercent              2\n",
       "HumidityLowPercent              2\n",
       "SeaLevelPressureHighInches      3\n",
       "SeaLevelPressureAvgInches       3\n",
       "SeaLevelPressureLowInches       3\n",
       "VisibilityHighMiles            12\n",
       "VisibilityAvgMiles             12\n",
       "VisibilityLowMiles             12\n",
       "WindHighMPH                     2\n",
       "WindAvgMPH                      2\n",
       "WindGustMPH                     4\n",
       "PrecipitationSumInches        124\n",
       "Events                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove this column from austin using the .drop() function. Use the inplace=True argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin.drop('PrecipitationSumInches', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will perform linear interpolation of the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_fixed = austin.interpolate(inplace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure austin_fixed contains no missing data. Also check austin - it still contains missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                           0\n",
       "TempHighF                      0\n",
       "TempAvgF                       0\n",
       "TempLowF                       0\n",
       "DewPointHighF                  7\n",
       "DewPointAvgF                   7\n",
       "DewPointLowF                   7\n",
       "HumidityHighPercent            2\n",
       "HumidityAvgPercent             2\n",
       "HumidityLowPercent             2\n",
       "SeaLevelPressureHighInches     3\n",
       "SeaLevelPressureAvgInches      3\n",
       "SeaLevelPressureLowInches      3\n",
       "VisibilityHighMiles           12\n",
       "VisibilityAvgMiles            12\n",
       "VisibilityLowMiles            12\n",
       "WindHighMPH                    2\n",
       "WindAvgMPH                     2\n",
       "WindGustMPH                    4\n",
       "Events                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                          0\n",
       "TempHighF                     0\n",
       "TempAvgF                      0\n",
       "TempLowF                      0\n",
       "DewPointHighF                 0\n",
       "DewPointAvgF                  0\n",
       "DewPointLowF                  0\n",
       "HumidityHighPercent           0\n",
       "HumidityAvgPercent            0\n",
       "HumidityLowPercent            0\n",
       "SeaLevelPressureHighInches    0\n",
       "SeaLevelPressureAvgInches     0\n",
       "SeaLevelPressureLowInches     0\n",
       "VisibilityHighMiles           0\n",
       "VisibilityAvgMiles            0\n",
       "VisibilityLowMiles            0\n",
       "WindHighMPH                   0\n",
       "WindAvgMPH                    0\n",
       "WindGustMPH                   0\n",
       "Events                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin_fixed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 3 - Processing the Events Column\n",
    "Our dataframe contains one true text column - the Events column. We should evaluate this column to determine how to process it.\n",
    "Use the value_counts() function to evaluate the contents of this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             903\n",
       "Rain                         192\n",
       "Rain , Thunderstorm          137\n",
       "Fog , Rain , Thunderstorm     33\n",
       "Fog                           21\n",
       "Thunderstorm                  17\n",
       "Fog , Rain                    14\n",
       "Rain , Snow                    1\n",
       "Fog , Thunderstorm             1\n",
       "Name: Events, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin_fixed['Events'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the largest number of events happened in a single day? Enter your answer in the next cell.\n",
    "\n",
    "3\n",
    "\n",
    "We want to transform the string-type Events values to the numbers. This will allow us to apply machine learning algorithms easily.\n",
    "How? We will create a new column for each type of events (i.e. Rain, Snow, Fog, Thunderstorm. In each column, we use 1 to indicate if the corresponding event happened in that day and use 0 otherwise.\n",
    "\n",
    "Below we provide you a list of all event types. Loop the list and create a dummy column with 0 values for each event in austin_fixed. To create a new dummy column with 0 values, simply use austin_fixed[event] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = ['Snow', 'Fog', 'Rain', 'Thunderstorm']\n",
    "\n",
    "austin_fixed[event_list] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, populate the actual values in the dummy columns of austin_fixed.\n",
    "You will check the Events column. If its string value contains Rain, then the Rain column should be 1. The same for Snow, Fog, and Thunderstorm.\n",
    "\n",
    "Hints:\n",
    "\n",
    "Use pandas.Series.str.contains() to create the value series of each new column.\n",
    "\n",
    "What if the values you populated are booleans instead of numbers? You can cast the boolean values to numbers by using .astype(int). For instance, pd.Series([True, True, False]).astype(int) will return a new series with values of [1, 1, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in event_list :\n",
    "    austin_fixed[event] = austin_fixed['Events'].str.contains(event).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out austin_fixed to check if the event columns are populated with the intended values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TempHighF</th>\n",
       "      <th>TempAvgF</th>\n",
       "      <th>TempLowF</th>\n",
       "      <th>DewPointHighF</th>\n",
       "      <th>DewPointAvgF</th>\n",
       "      <th>DewPointLowF</th>\n",
       "      <th>HumidityHighPercent</th>\n",
       "      <th>HumidityAvgPercent</th>\n",
       "      <th>HumidityLowPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>VisibilityAvgMiles</th>\n",
       "      <th>VisibilityLowMiles</th>\n",
       "      <th>WindHighMPH</th>\n",
       "      <th>WindAvgMPH</th>\n",
       "      <th>WindGustMPH</th>\n",
       "      <th>Events</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Rain , Thunderstorm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>58</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>61</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-12-26</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-12-28</td>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-12-29</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>51.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>71</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  TempHighF  TempAvgF  TempLowF  DewPointHighF  DewPointAvgF  \\\n",
       "0   2013-12-21         74        60        45           67.0          49.0   \n",
       "1   2013-12-22         56        48        39           43.0          36.0   \n",
       "2   2013-12-23         58        45        32           31.0          27.0   \n",
       "3   2013-12-24         61        46        31           36.0          28.0   \n",
       "4   2013-12-25         58        50        41           44.0          40.0   \n",
       "5   2013-12-26         57        48        39           39.0          36.0   \n",
       "6   2013-12-27         60        53        45           41.0          39.0   \n",
       "7   2013-12-28         62        51        40           43.0          39.0   \n",
       "8   2013-12-29         64        50        36           49.0          41.0   \n",
       "9   2013-12-30         44        40        35           31.0          26.0   \n",
       "10  2013-12-31         55        46        36           31.0          28.0   \n",
       "11  2014-01-01         69        54        39           51.0          42.0   \n",
       "12  2014-01-02         55        44        33           39.0          26.0   \n",
       "13  2014-01-03         58        43        28           37.0          22.0   \n",
       "14  2014-01-04         71        57        42           55.0          48.0   \n",
       "15  2014-01-05         59        47        34           54.0          32.0   \n",
       "16  2014-01-06         36        29        22           15.0           8.0   \n",
       "17  2014-01-07         48        35        22           29.0          11.0   \n",
       "18  2014-01-08         53        47        40           51.0          45.0   \n",
       "19  2014-01-09         70        62        53           60.0          55.0   \n",
       "\n",
       "    DewPointLowF  HumidityHighPercent  HumidityAvgPercent  HumidityLowPercent  \\\n",
       "0           43.0                 93.0                75.0                57.0   \n",
       "1           28.0                 93.0                68.0                43.0   \n",
       "2           23.0                 76.0                52.0                27.0   \n",
       "3           21.0                 89.0                56.0                22.0   \n",
       "4           36.0                 86.0                71.0                56.0   \n",
       "5           33.0                 79.0                63.0                47.0   \n",
       "6           37.0                 83.0                65.0                47.0   \n",
       "7           33.0                 92.0                64.0                36.0   \n",
       "8           28.0                 92.0                76.0                60.0   \n",
       "9           21.0                 75.0                60.0                45.0   \n",
       "10          23.0                 76.0                54.0                32.0   \n",
       "11          30.0                 83.0                68.0                52.0   \n",
       "12          19.0                 83.0                55.0                26.0   \n",
       "13          18.0                 75.0                49.0                22.0   \n",
       "14          38.0                 89.0                68.0                47.0   \n",
       "15          15.0                 87.0                59.0                31.0   \n",
       "16           2.0                 50.0                38.0                26.0   \n",
       "17           4.0                 68.0                43.0                17.0   \n",
       "18          30.0                 93.0                75.0                57.0   \n",
       "19          50.0                 93.0                80.0                66.0   \n",
       "\n",
       "    ...  VisibilityAvgMiles  VisibilityLowMiles  WindHighMPH  WindAvgMPH  \\\n",
       "0   ...                 7.0                 2.0         20.0         4.0   \n",
       "1   ...                10.0                 5.0         16.0         6.0   \n",
       "2   ...                10.0                10.0          8.0         3.0   \n",
       "3   ...                10.0                 7.0         12.0         4.0   \n",
       "4   ...                10.0                 7.0         10.0         2.0   \n",
       "5   ...                 9.0                 7.0         12.0         3.0   \n",
       "6   ...                 9.0                 7.0          7.0         1.0   \n",
       "7   ...                10.0                 7.0         10.0         2.0   \n",
       "8   ...                10.0                 4.0         17.0         5.0   \n",
       "9   ...                10.0                10.0         13.0         5.0   \n",
       "10  ...                10.0                10.0          8.0         1.0   \n",
       "11  ...                10.0                 8.0         13.0         4.0   \n",
       "12  ...                10.0                 9.0         21.0         8.0   \n",
       "13  ...                10.0                10.0         14.0         4.0   \n",
       "14  ...                10.0                 8.0         16.0         7.0   \n",
       "15  ...                10.0                 4.0         21.0        10.0   \n",
       "16  ...                10.0                10.0         17.0         7.0   \n",
       "17  ...                10.0                10.0         13.0         5.0   \n",
       "18  ...                 2.0                 1.0         12.0         1.0   \n",
       "19  ...                 4.0                 0.0         12.0         3.0   \n",
       "\n",
       "    WindGustMPH               Events  Snow  Fog  Rain Thunderstorm  \n",
       "0          31.0  Rain , Thunderstorm     0    0     1            1  \n",
       "1          25.0                          0    0     0            0  \n",
       "2          12.0                          0    0     0            0  \n",
       "3          20.0                          0    0     0            0  \n",
       "4          16.0                          0    0     0            0  \n",
       "5          17.0                          0    0     0            0  \n",
       "6          11.0                          0    0     0            0  \n",
       "7          14.0                          0    0     0            0  \n",
       "8          24.0                          0    0     0            0  \n",
       "9          21.0                          0    0     0            0  \n",
       "10         12.0                          0    0     0            0  \n",
       "11         22.0                          0    0     0            0  \n",
       "12         31.0                          0    0     0            0  \n",
       "13         21.0                          0    0     0            0  \n",
       "14         28.0                          0    0     0            0  \n",
       "15         34.0                          0    0     0            0  \n",
       "16         27.0                          0    0     0            0  \n",
       "17         22.0                          0    0     0            0  \n",
       "18         18.0                 Rain     0    0     1            0  \n",
       "19         19.0                  Fog     0    1     0            0  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin_fixed.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code worked correctly, now we can drop the Events column as we don't need it any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_fixed.drop('Events', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 4 - Processing The Date Column\n",
    "The Date column is another non-numeric field in our dataset. A value in that field looks like '2014-01-06' which consists of the year, month, and day connected with hyphens. One way to convert the date string to numerical is using a similar approach as we used for Events, namely splitting the column into numerical Year, Month, and Day columns. In this challenge we'll show you another way which is to use the Python datetime library's toordinal() function. Depending on what actual machine learning analysis you will conduct, each approach has its pros and cons. Our goal today is to practice data preparation so we'll skip the discussion here.\n",
    "\n",
    "Here you can find the reference and example for toordinal. The basic process is to first convert the string to a datetime object using datetime.datetime.strptime, then convert the datetime object to numerical using toordinal.\n",
    "\n",
    "In the cell below, convert the Date column values from string to numeric values using toordinal()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_fixed['Date'] = austin_fixed['Date'].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d').toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    735223\n",
       "1    735224\n",
       "2    735225\n",
       "3    735226\n",
       "4    735227\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austin_fixed['Date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 5 - Sampling and Holdout Sets\n",
    "Now that we have processed the data for machine learning, we will separate the data to test and training sets.\n",
    "\n",
    "We first train the model using only the training set. We check our metrics on the training set. We then apply the model to the test set and check our metrics on the test set as well. If the metrics are significantly more optimal on the training set, then we know we have overfit our model. We will need to revise our model to ensure it will be more applicable to data outside the test set.\n",
    "\n",
    "In the next cells we will separate the data into a training set and a test set using the train_test_split() function in scikit-learn.\n",
    "\n",
    "When using scikit-learn for machine learning, we first separate the data to predictor and response variables. This is the standard way of passing datasets into a model in scikit-learn. The scikit-learn will then find out whether the predictors and responses fit the model.\n",
    "\n",
    "In the next cell, assign the TempAvgF column to y and the remaining columns to X. Your X should be a subset of austin_fixed containing the following columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = austin_fixed['TempAvgF']\n",
    "x_columns = ['Date', 'TempHighF', 'TempLowF', 'DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', 'SeaLevelPressureAvgInches', 'SeaLevelPressureLowInches', 'VisibilityHighMiles', 'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', 'WindGustMPH', 'Snow', 'Fog', 'Rain', 'Thunderstorm']\n",
    "X = austin_fixed[x_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, import train_test_split from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data to predictor and response variables and imported the train_test_split() function, split X and y into X_train, X_test, y_train, and y_test. 80% of the data should be in the training set and 20% in the test set. train_test_split() reference can be accessed here.\n",
    "\n",
    "Enter your code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Challenge 1\n",
    "While the above is the common practice to prepare most datasets, when it comes to time series data, we sometimes do not want to randomly select rows from our dataset.\n",
    "This is because many time series algorithms rely on observations having equal time distances between them. In such cases, we typically select the majority of rows as the test data and the last few rows as the training data. We don't use train_test_split() to select the train/test data because it returns random selections.\n",
    "\n",
    "In the following cell, compute the number of rows that account for 80% of our data and round it to the next integer. Assign this number to ts_rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.8 * austin_fixed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts_train = X[:1055]\n",
    "y_ts_train = y[:1055]\n",
    "X_ts_test = X[1055:]\n",
    "y_ts_test = y[1055:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Challenge 2\n",
    "As explained in the README, the main purpose of this lab is to show you the typical process of preparing data for machine learning which sometimes takes up 90% of your time. Data cleaning is a valuable skill to learn and you need to be proficient at various techniques including the ones we showed you above as well as others you'll learn in the future. In the real world this skill will help you perform your job successfully and efficiently.\n",
    "\n",
    "Now that we're done with data praparation, if you want to expeirence what you'll do in the rest 10% of your time, let's make the final leap.\n",
    "\n",
    "We will use scikit-learn's Support Vector Machines to compute the fit of our training data set, the test on our test data set.\n",
    "\n",
    "In the cell below, import svm from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call svm.SVC.fit() on X_train and y_train. Assign the returned value to a variable called clf which stands for classifier. Then obtain the test score for X_test and y_test by calling clf.score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015151515151515152"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = clf.fit(X_train, y_train)\n",
    "\n",
    "c.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now see the model fit score of your test data set. If it's extremely low, it means your selected model is not a good fit and you should try other models.\n",
    "In addition to fitting X_train, y_train, X_test, and y_test, you can also fit X_ts_train, y_ts_train, X_ts_test, and y_ts_test if you completed Bonus Challenge 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015151515151515152"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_ts = clf.fit(X_ts_train, y_ts_train)\n",
    "\n",
    "c_ts.score(X_ts_test, y_ts_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d17122d79747f4b383b2c6abff0c2edbb0c56782714054fbb4f5a4e0962ae7a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
